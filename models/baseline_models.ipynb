{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "- Using three baseline models for the development of an analysis that detects political language in court documents.\n",
    "    1. Logistic regression\n",
    "    2. Naive Bayes\n",
    "    3. SVM\n",
    "- Using baselines as a means for testing model performance and building an accurate, model for classifying language used in Bulgaria's constitutional court\n",
    "\n",
    "## Next steps\n",
    "\n",
    "- Data needs more sentences labelled as political, as data is imbalanced and models observe few political sentences\n",
    "- Need to optimize hyperparameters to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/paulj1989/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfD4 = pd.read_json(\"data/json/D4_060493.json\")\n",
    "dfD8 = pd.read_json(\"data/json/D8_081002.json\")\n",
    "dfD9 = pd.read_json(\"data/json/D9_241002.json\")\n",
    "dfD10 = pd.read_json(\"data/json/D10_100501.json\")\n",
    "dfD12 = pd.read_json(\"data/json/D12_220501.json\")\n",
    "dfD14 = pd.read_json(\"data/json/D14_120995.json\")\n",
    "dfD17 = pd.read_json(\"data/json/D17_241192.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column identifying documents\n",
    "dfD4['doc_id'] = 'D4_060493'\n",
    "dfD8['doc_id'] = 'D8_081002'\n",
    "dfD9['doc_id'] = 'D9_241002'\n",
    "dfD10['doc_id'] = 'D10_100501'\n",
    "dfD12['doc_id'] = 'D12_220501'\n",
    "dfD14['doc_id'] = 'D14_120995'\n",
    "dfD17['doc_id'] = \"D17_241192\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all dataframes\n",
    "df = pd.concat([dfD4, dfD8, dfD9, dfD10, dfD12, dfD14, dfD17], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary variable where POLITICAL = 1, all else = 0\n",
    "df.loc[df[\"label_id\"] != 4, \"label_id\"] = 0\n",
    "\n",
    "df.loc[df[\"label_id\"] == 4, \"label_id\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in text.lower().split() if not word in stop_words]\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paragraph_id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>label_id</th>\n      <th>description</th>\n      <th>doc_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>solution ne 5 6 april 1993 cd ne 693 interpret...</td>\n      <td>BACKGROUND</td>\n      <td>0</td>\n      <td>CASE TITLE</td>\n      <td>D4_060493</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>members asen manov chairman mladen danailov ts...</td>\n      <td>BACKGROUND</td>\n      <td>0</td>\n      <td>CASE TITLE</td>\n      <td>D4_060493</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>proceedings instituted request 52 mps 36th nat...</td>\n      <td>SUMMARY</td>\n      <td>0</td>\n      <td>REFERRAL</td>\n      <td>D4_060493</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>order 2 march 1993 constitutional court grante...</td>\n      <td>SUMMARY</td>\n      <td>0</td>\n      <td>REFERRAL</td>\n      <td>D4_060493</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>authors request instructed clarify issues view...</td>\n      <td>SUMMARY</td>\n      <td>0</td>\n      <td>REFERRAL</td>\n      <td>D4_060493</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>366</th>\n      <td>32</td>\n      <td>provision art 2 para higher education act must...</td>\n      <td>CONSTITUTIONAL INTERPRETATION</td>\n      <td>0</td>\n      <td>None</td>\n      <td>D17_241192</td>\n    </tr>\n    <tr>\n      <th>367</th>\n      <td>33</td>\n      <td>national assembly authorized legalize public h...</td>\n      <td>CONSTITUTIONAL INTERPRETATION</td>\n      <td>0</td>\n      <td>None</td>\n      <td>D17_241192</td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>34</td>\n      <td>provision art 2 para zvo unconstitutional alle...</td>\n      <td>POLITICAL</td>\n      <td>1</td>\n      <td>MORAL/POLITICAL JUDGEMENT OF NATIONAL ASSEMBLY...</td>\n      <td>D17_241192</td>\n    </tr>\n    <tr>\n      <th>369</th>\n      <td>35</td>\n      <td>authors request opinions allege infringements ...</td>\n      <td>FACTUAL</td>\n      <td>0</td>\n      <td>ROLE/SCOPE OF THE COURT</td>\n      <td>D17_241192</td>\n    </tr>\n    <tr>\n      <th>370</th>\n      <td>36</td>\n      <td>due grounds art 149 para 1 item 2 constitution...</td>\n      <td>DECISION</td>\n      <td>0</td>\n      <td>CASE RESOLVED</td>\n      <td>D17_241192</td>\n    </tr>\n  </tbody>\n</table>\n<p>371 rows Ã— 6 columns</p>\n</div>",
      "text/plain": "     paragraph_id                                               text  \\\n0               1  solution ne 5 6 april 1993 cd ne 693 interpret...   \n1               2  members asen manov chairman mladen danailov ts...   \n2               3  proceedings instituted request 52 mps 36th nat...   \n3               4  order 2 march 1993 constitutional court grante...   \n4               5  authors request instructed clarify issues view...   \n..            ...                                                ...   \n366            32  provision art 2 para higher education act must...   \n367            33  national assembly authorized legalize public h...   \n368            34  provision art 2 para zvo unconstitutional alle...   \n369            35  authors request opinions allege infringements ...   \n370            36  due grounds art 149 para 1 item 2 constitution...   \n\n                             label  label_id  \\\n0                       BACKGROUND         0   \n1                       BACKGROUND         0   \n2                          SUMMARY         0   \n3                          SUMMARY         0   \n4                          SUMMARY         0   \n..                             ...       ...   \n366  CONSTITUTIONAL INTERPRETATION         0   \n367  CONSTITUTIONAL INTERPRETATION         0   \n368                      POLITICAL         1   \n369                        FACTUAL         0   \n370                       DECISION         0   \n\n                                           description      doc_id  \n0                                           CASE TITLE   D4_060493  \n1                                           CASE TITLE   D4_060493  \n2                                             REFERRAL   D4_060493  \n3                                             REFERRAL   D4_060493  \n4                                             REFERRAL   D4_060493  \n..                                                 ...         ...  \n366                                               None  D17_241192  \n367                                               None  D17_241192  \n368  MORAL/POLITICAL JUDGEMENT OF NATIONAL ASSEMBLY...  D17_241192  \n369                            ROLE/SCOPE OF THE COURT  D17_241192  \n370                                      CASE RESOLVED  D17_241192  \n\n[371 rows x 6 columns]"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_rows', 371)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def token_ps(text):\n",
    "    return [ps.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "- Computing a logistic regression model based on the values created from a vectorizer algorithm called tf-idf, which stands for term-frequency inverse document frequency.\n",
    "- tf-idf measures the originality of the word by comparing how often it appears in a doc with the number of docs the word appears in. The frequency of the words in a doc (compared against other docs) measures the importance of that word in the wider corpus.\n",
    "- The logistic regression below is computed by building a vector of word values based on the iportance of each word, before using the word vectors to identify the characteristics of the political label to predict which sentences will be political."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming text into vectors\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None,\n",
    "                        use_idf=True,\n",
    "                        norm='l2',\n",
    "                        smooth_idf=True)\n",
    "# compute tfidf values for all words in 'text' column of df\n",
    "X = tfidf.fit_transform(df['text'])\n",
    "y = df.label_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.9s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.3s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.8s finished\n"
     ]
    }
   ],
   "source": [
    "# splitting data into train and test splits in order to test predictive accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0, test_size=0.3, shuffle=True\n",
    ")\n",
    "\n",
    "# computes and then fits logistic regression that implements cross-validation as a part of the process\n",
    "# cv = number of cross validation folds\n",
    "log_reg = LogisticRegressionCV(\n",
    "    cv=10, scoring=\"accuracy\", n_jobs=-1, verbose=3, max_iter=500\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# model accuracy\n",
    "log_predictions = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that prints model prediction accuracy\n",
    "def model_accuracy(name, preds):\n",
    "    print(\"---{} Test Set Results---\".format(name))\n",
    "    print(\"Weighted F1 Average: {}\".format(f1_score(y_test, preds, average=\"weighted\")))\n",
    "    # precision = % predicted accurately\n",
    "    # recall = % positives identified\n",
    "    # f1-score = weighted harmonic mean of precision & recall\n",
    "    # weighted f-1 avg used for comparing classification models\n",
    "    print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Logit Test Set Results---\n",
      "Weighted F1 Average: 0.8372408293460925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        98\n",
      "           1       1.00      0.07      0.13        14\n",
      "\n",
      "    accuracy                           0.88       112\n",
      "   macro avg       0.94      0.54      0.54       112\n",
      "weighted avg       0.90      0.88      0.84       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(\"Logit\", log_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tfidf values for all words in 'text' column of df\n",
    "# .toarray() added in this instance to adjus the way the data is structured\n",
    "# for nb model to run without error\n",
    "X = tfidf.fit_transform(df[\"text\"]).toarray()\n",
    "y = df.label_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test splits in order to test predictive accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0, test_size=0.3, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Naive Bayes Test Set Results---\n",
      "Weighted F1 Average: 0.8166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        98\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.88       112\n",
      "   macro avg       0.44      0.50      0.47       112\n",
      "weighted avg       0.77      0.88      0.82       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# model accuracy\n",
    "nb_predictions = nb.predict(X_test)\n",
    "model_accuracy(\"Naive Bayes\", nb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SVM Test Set Results---\n",
      "Weighted F1 Average: 0.8166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        98\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.88       112\n",
      "   macro avg       0.44      0.50      0.47       112\n",
      "weighted avg       0.77      0.88      0.82       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the SVM classifier\n",
    "SVM = svm.SVC(C=1.0, kernel=\"linear\", degree=3, gamma=\"auto\")\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "# model accuracy\n",
    "svm_predictions = SVM.predict(X_test)\n",
    "model_accuracy(\"SVM\", svm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling Models (for Future Use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving tfidf\n",
    "pickle.dump(tfidf, open('tfidf.pickle', 'wb'))\n",
    "\n",
    "# saving models\n",
    "pickle.dump(log_reg, open('log_reg.pickle', 'wb'))\n",
    "pickle.dump(nb, open('nb.pickle', 'wb'))\n",
    "pickle.dump(SVM, open('svm.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('bulgarian-constitutional-court-decisions': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "9e35bad0b5aa7a87571eaa6bfdcd491c11984b99cb58639a3f82d97f7d8977e2"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}