{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "- Using three baseline models for the development of an analysis that detects political language in court documents.\n",
    "    1. Logistic regression\n",
    "    2. Naive Bayes\n",
    "    3. SVM\n",
    "- Using baselines as a means for testing model performance and building an accurate, model for classifying language used in Bulgaria's constitutional court\n",
    "\n",
    "## Next steps\n",
    "\n",
    "- Data needs more sentences labelled as political, as data is imbalanced and models observe few political sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/paulj1989/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfD4 = pd.read_json(\"data/json/D4_060493.json\")\n",
    "dfD8 = pd.read_json(\"data/json/D8_081002.json\")\n",
    "dfD9 = pd.read_json(\"data/json/D9_241002.json\")\n",
    "dfD10 = pd.read_json(\"data/json/D10_100501.json\")\n",
    "dfD12 = pd.read_json(\"data/json/D12_220501.json\")\n",
    "dfD14 = pd.read_json(\"data/json/D14_120995.json\")\n",
    "dfD17 = pd.read_json(\"data/json/D17_241192.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column identifying documents\n",
    "dfD4['doc_id'] = 'D4_060493'\n",
    "dfD8['doc_id'] = 'D8_081002'\n",
    "dfD9['doc_id'] = 'D9_241002'\n",
    "dfD10['doc_id'] = 'D10_100501'\n",
    "dfD12['doc_id'] = 'D12_220501'\n",
    "dfD14['doc_id'] = 'D14_120995'\n",
    "dfD17['doc_id'] = \"D17_241192\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all dataframes\n",
    "df = pd.concat([dfD4, dfD8, dfD9, dfD10, dfD12, dfD14, dfD17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary variable where POLITICAL = 1, all else = 0\n",
    "df.loc[df[\"label_id\"] != 4, \"label_id\"] = 0\n",
    "\n",
    "df.loc[df[\"label_id\"] == 4, \"label_id\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in text.lower().split() if not word in stop_words]\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def token_ps(text):\n",
    "    return [ps.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "- Computing a logistic regression model based on the values created from a vectorizer algorithm called tf-idf, which stands for term-frequency inverse document frequency.\n",
    "- tf-idf measures the originality of the word by comparing how often it appears in a doc with the number of docs the word appears in. The frequency of the words in a doc (compared against other docs) measures the importance of that word in the wider corpus.\n",
    "- The logistic regression below is computed by building a vector of word values based on the iportance of each word, before using the word vectors to identify the characteristics of the political label to predict which sentences will be political."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming text into vectors\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None,\n",
    "                        tokenizer=token_ps,\n",
    "                        use_idf=True,\n",
    "                        norm='l2',\n",
    "                        smooth_idf=True)\n",
    "# compute tfidf values for all words in 'text' column of df\n",
    "X = tfidf.fit_transform(df['text'])\n",
    "y = df.label_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.1s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test Set Results---\n",
      "Accuracy with logreg: 0.8118279569892473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90       151\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.81       186\n",
      "   macro avg       0.41      0.50      0.45       186\n",
      "weighted avg       0.66      0.81      0.73       186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting data into train and test splits in order to test predictive accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "# computes and then fits logistic regression that implements cross-validation as a part of the process\n",
    "# cv = number of cross validation folds\n",
    "clf = LogisticRegressionCV(\n",
    "    cv=10, scoring=\"accuracy\", n_jobs=-1, verbose=3, max_iter=500\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# save the model - meaning it doesn't need to be trained every time\n",
    "logit_model = open(\"logit_model.sav\", \"wb\")\n",
    "pickle.dump(clf, logit_model)\n",
    "logit_model.close()\n",
    "\n",
    "# presenting model accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tfidf values for all words in 'text' column of df\n",
    "# .toarray() added in this instance to adjus the way the data is structured\n",
    "# for nb model to run without error\n",
    "X = tfidf.fit_transform(df[\"text\"]).toarray()\n",
    "y = df.label_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test splits in order to test predictive accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test Set Results---\n",
      "Naive Bayes Accuracy: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        54\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.72        75\n",
      "   macro avg       0.36      0.50      0.42        75\n",
      "weighted avg       0.52      0.72      0.60        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "# presenting model accuracy\n",
    "y_pred = nb.predict(X_test)\n",
    "print(\"---Test Set Results---\")\n",
    "print(\"Naive Bayes Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test Set Results---\n",
      "SVM Accuracy: 0.8035714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        90\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.40      0.50      0.45       112\n",
      "weighted avg       0.65      0.80      0.72       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the SVM classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train,y_train)\n",
    "\n",
    "# presenting model accuracy\n",
    "y_pred_svm = SVM.predict(X_test)\n",
    "print(\"---Test Set Results---\")\n",
    "print(\"SVM Accuracy: {}\".format(accuracy_score(y_test, y_pred_svm)))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('bulgarian-constitutional-court-decisions': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "9e35bad0b5aa7a87571eaa6bfdcd491c11984b99cb58639a3f82d97f7d8977e2"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}