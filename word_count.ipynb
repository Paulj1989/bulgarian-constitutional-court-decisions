{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Full Court Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/paulj1989/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/paulj1989/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"wordnet\") \n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "courtfile = open(\"/home/paulj1989/Repositories/Github/bulgarian-constitutional-court-decisions/data/all_txt_data.txt\")\n",
    "courttext = courtfile.read()\n",
    "courtfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def clean(x):\n",
    "    x = x.lower()\n",
    "    x = re.sub('[.!?/+{}\\\\\\\\,<©]+', ' ', x)\n",
    "    x = re.sub(r'[0-9]+', \" \", x)\n",
    "    x = x.split()\n",
    "    x = [word for word in x if word not in stopwords.words('english')]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "court_words = clean(courttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         'internal': 14,\n         'inherent': 18,\n         'qualities': 12,\n         'proclaimed': 41,\n         'documents': 113,\n         'declaration': 30,\n         'covenant': 11,\n         'civil': 167,\n         'protocol)': 1,\n         'worded': 3,\n         'positive': 7,\n         'march': 34,\n         'ei-movsh': 1,\n         'apd': 1,\n         'setzau': 1,\n         'area': 89,\n         'abstain': 1,\n         'non-interference': 4,\n         'taking': 33,\n         'g': 16,\n         '“': 25,\n         'exists': 6,\n         'produce': 6,\n         'hold': 35,\n         'manner': 38,\n         'includes': 42,\n         'creation': 41,\n         'information': 258,\n         'value': 38,\n         'capacity': 30,\n         'officials': 9,\n         'parties': 183,\n         'receive': 47,\n         'privileged': 2,\n         'appearances': 2,\n         'others': 68,\n         'electronic': 8,\n         'media': 28,\n         'publication': 7,\n         'response': 3,\n         'infringement': 7,\n         'good': 26,\n         'name': 67,\n         'periodical': 1,\n         'freely': 14,\n         'availability': 6,\n         'pressure': 8,\n         'participate': 50,\n         'informed': 4,\n         'choice': 16,\n         'especially': 19,\n         'purposes': 12,\n         'existing': 110,\n         'applicants': 69,\n         'contestants': 1,\n         'persecuted': 1,\n         'disadvantaged': 3,\n         'participants': 17,\n         'khan': 1,\n         'tite': 1,\n         '”for': 1,\n         'elect': 11,\n         'citizenship': 2,\n         'reached': 5,\n         'age': 10,\n         'placed': 20,\n         'guardianship': 5,\n         'serving': 4,\n         'imprisonment': 4,\n         'broadly': 2,\n         'suspected': 3,\n         'instituted': 20,\n         'moreover': 34,\n         'since': 41,\n         '“restrictions': 1,\n         'excess': 3,\n         'taken': 64,\n         'together': 7,\n         'opening': 6,\n         'exist': 24,\n         'goes': 4,\n         'beyond': 15,\n         ...})"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "Counter(court_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'art': 2521,\n 'law': 2050,\n 'para': 1892,\n 'constitution': 1563,\n 'constitutional': 1348,\n 'state': 1328,\n 'court': 1148,\n '-': 1133,\n 'article': 1111,\n 'right': 847,\n 'property': 788,\n 'legal': 779,\n 'provision': 678,\n 'paragraph': 664,\n 'national': 650,\n 'rights': 623,\n 'act': 579,\n 'request': 575,\n 'case': 574,\n 'decision': 540,\n '§': 523,\n 'public': 504,\n 'according': 502,\n 'item': 481,\n 'also': 463,\n 'provisions': 457,\n 'assembly': 440,\n 'budget': 413,\n 'council': 368,\n 'bulgaria': 367,\n 'part': 363,\n 'general': 362,\n 'protection': 361,\n 'one': 360,\n 'ministers': 344,\n 'supreme': 341,\n '№': 341,\n ')': 337,\n 'activity': 330,\n 'judiciary': 328,\n 'municipal': 324,\n 'administrative': 323,\n 'republic': 313,\n 'citizens': 313,\n 'order': 311,\n 'provided': 305,\n 'security': 300,\n 'minister': 293,\n 'principle': 289,\n 'health': 285}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "common_words = dict(Counter(\" \".join(court_words).split()).most_common(50))\n",
    "\n",
    "common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Using Spacy & Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.load(\"en_core_web_sm\")\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code not working - Figure out why\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meanings of words, synonyms, antonyms etc. & root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the text for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Text is Converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-17fe7a691770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_text_for_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
     ]
    }
   ],
   "source": [
    "text_data = []\n",
    "with open('dataset.csv') as f:\n",
    "    for line in f:\n",
    "        tokens = prepare_text_for_lda(line)\n",
    "        if random.random() > .99:\n",
    "            print(tokens)\n",
    "            text_data.append(tokens)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}